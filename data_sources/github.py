"""GitHub æ•°æ®æº"""
import asyncio
import logging
from typing import Dict, Any
import pendulum
import requests

logger = logging.getLogger(__name__)
TIMEZONE = "Asia/Shanghai"


def _get_repo_name_from_url(url):
    """ä»ä»“åº“ URL ä¸­æå–ä»“åº“åç§°"""
    return "/".join(url.split("/")[-2:])


def _make_api_request(url, headers, params=None):
    """ç»Ÿä¸€çš„ API è¯·æ±‚å‡½æ•°"""
    try:
        response = requests.get(url, headers=headers, params=params)
        if response.status_code == 200:
            return response.json(), None
        else:
            return None, f"API è¯·æ±‚å¤±è´¥: {response.status_code}"
    except Exception as e:
        return None, f"è¯·æ±‚å‡ºé”™: {e}"


def _process_search_items(items, username, item_type):
    """å¤„ç†æœç´¢ç»“æœï¼ˆPR æˆ– Issueï¼‰"""
    activities = []
    action_text = "åˆ›å»ºäº† PR" if item_type == "pr" else "åˆ›å»ºäº† Issue"

    for item in items:
        try:
            user = item.get("user", {})
            if user.get("login") == username:
                repo_url = item.get("repository_url", "")
                repo_name = _get_repo_name_from_url(repo_url) if repo_url else "Unknown"
                title = item.get("title", "No title")
                url = item.get("html_url", "")
                activities.append({
                    "type": item_type,
                    "action": "created",
                    "title": title,
                    "url": url,
                    "repo": repo_name,
                })
        except Exception as e:
            logger.warning(f"å¤„ç† {item_type} æ•°æ®æ—¶å‡ºé”™: {e}")
            continue

    return activities


def _process_events(events, yesterday_start, yesterday_end):
    """å¤„ç†ç”¨æˆ·äº‹ä»¶"""
    activities = []

    logger.info(f"å¼€å§‹å¤„ç†äº‹ä»¶ï¼Œæ—¶é—´èŒƒå›´: {yesterday_start} åˆ° {yesterday_end}")
    logger.info(f"æ”¶åˆ° {len(events)} ä¸ªäº‹ä»¶")

    for event in events[:100]:
        try:
            created_at = event.get("created_at")
            if not created_at:
                continue

            event_created = pendulum.parse(created_at)

            if event_created < yesterday_start:
                logger.debug(f"äº‹ä»¶æ—¶é—´ {event_created} æ—©äºèµ·å§‹æ—¶é—´ï¼Œåœæ­¢å¤„ç†")
                break

            if not (yesterday_start <= event_created <= yesterday_end):
                logger.debug(f"äº‹ä»¶æ—¶é—´ {event_created} ä¸åœ¨ç›®æ ‡èŒƒå›´å†…")
                continue

            if not event.get("public", True):
                logger.debug("è·³è¿‡ç§æœ‰äº‹ä»¶")
                continue

            event_type = event.get("type")
            if not event_type:
                continue

            repo = event.get("repo", {})
            repo_name = repo.get("name", "Unknown")

            logger.debug(f"å¤„ç†äº‹ä»¶: type={event_type}, repo={repo_name}, time={event_created}")

            if event_type == "PullRequestEvent":
                action = event.get("payload", {}).get("action")
                pr_data = event.get("payload", {}).get("pull_request", {})

                logger.info(f"PullRequestEvent: action={action}, merged={pr_data.get('merged')}, repo={repo_name}")

                # GitHub API ä¸¤ç§æƒ…å†µéƒ½è¦æ”¯æŒï¼š
                # 1. action="merged" (æŸäº› webhook äº‹ä»¶)
                # 2. action="closed" ä¸” pull_request.merged=true (æ ‡å‡† Events API)
                is_merged = (
                    action == "merged" or
                    (action == "closed" and pr_data.get("merged") is True)
                )

                if is_merged:
                    # å¦‚æœ pr_data ä¸ºç©ºï¼Œå°è¯•ä»å…¶ä»–åœ°æ–¹è·å–ä¿¡æ¯
                    title = pr_data.get("title") if pr_data else None
                    url = pr_data.get("html_url") if pr_data else None

                    # å¦‚æœæ²¡æœ‰è¯¦ç»†æ•°æ®ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                    if not title:
                        title = f"PR in {repo_name}"
                        logger.warning(f"PR ç¼ºå°‘å®Œæ•´æ•°æ®ï¼Œä½¿ç”¨ä»“åº“åç§°ä½œä¸ºæ ‡é¢˜")

                    logger.info(f"âœ… æ‰¾åˆ°åˆå¹¶çš„ PR: {title}")
                    activities.append({
                        "type": "pr",
                        "action": "merged",
                        "title": title,
                        "url": url or f"https://github.com/{repo_name}",
                        "repo": repo_name,
                    })
                else:
                    logger.debug(f"PR ä¸ç¬¦åˆåˆå¹¶æ¡ä»¶: action={action}, merged={pr_data.get('merged')}")
            elif event_type == "IssuesEvent":
                action = event.get("payload", {}).get("action")
                if action == "closed":
                    issue_data = event.get("payload", {}).get("issue", {})
                    activities.append({
                        "type": "issue",
                        "action": "closed",
                        "title": issue_data.get("title", "No title"),
                        "url": issue_data.get("html_url", ""),
                        "repo": repo_name,
                    })
            elif event_type == "WatchEvent":
                action = event.get("payload", {}).get("action")
                if action == "started":
                    activities.append({
                        "type": "star",
                        "action": "starred",
                        "repo": repo_name,
                        "url": f"https://github.com/{repo_name}",
                    })
            elif event_type == "PushEvent":
                # ç»Ÿè®¡ commits
                commits_count = len(event.get("payload", {}).get("commits", []))
                if commits_count > 0:
                    activities.append({
                        "type": "push",
                        "action": "pushed",
                        "commits": commits_count,
                        "repo": repo_name,
                    })
        except Exception as e:
            logger.warning(f"å¤„ç†äº‹ä»¶æ—¶å‡ºé”™: {e}")
            continue

    logger.info(f"äº‹ä»¶å¤„ç†å®Œæˆï¼Œå…±æ‰¾åˆ° {len(activities)} ä¸ªæ´»åŠ¨")
    return activities


def _calculate_streak(username: str, headers: Dict[str, str]) -> int:
    """è®¡ç®—è¿ç»­è´¡çŒ®å¤©æ•°ï¼ˆæœ€è¿‘7å¤©ï¼‰

    Args:
        username: GitHub ç”¨æˆ·å
        headers: API è¯·æ±‚å¤´

    Returns:
        int: è¿ç»­è´¡çŒ®å¤©æ•°
    """
    try:
        now = pendulum.now(TIMEZONE)
        events_url = f"https://api.github.com/users/{username}/events"

        # è·å–æœ€è¿‘çš„äº‹ä»¶ï¼ˆå¤šè·å–å‡ é¡µä»¥ç¡®ä¿è¦†ç›–7å¤©ï¼‰
        all_events = []
        for page in range(1, 6):  # è·å–5é¡µï¼Œæ¯é¡µ30ä¸ªäº‹ä»¶
            events_data, error = _make_api_request(
                events_url,
                headers,
                {"page": page, "per_page": 30}
            )

            if error or not events_data:
                break

            all_events.extend(events_data)

            if len(events_data) < 30:
                break

        # æŒ‰æ—¥æœŸåˆ†ç»„æ´»åŠ¨
        activity_dates = set()
        for event in all_events:
            try:
                created_at = event.get("created_at")
                if created_at:
                    event_time = pendulum.parse(created_at).in_timezone(TIMEZONE)
                    # åªè®°å½•æ—¥æœŸï¼ˆå¹´-æœˆ-æ—¥ï¼‰
                    date_str = event_time.format("YYYY-MM-DD")
                    activity_dates.add(date_str)
            except Exception as e:
                logger.debug(f"è§£æäº‹ä»¶æ—¶é—´å‡ºé”™: {e}")
                continue

        logger.info(f"æœ€è¿‘æœ‰æ´»åŠ¨çš„æ—¥æœŸ: {sorted(activity_dates, reverse=True)[:7]}")

        # ä»æ˜¨å¤©å¼€å§‹å¾€å›æŸ¥ï¼Œè®¡ç®—è¿ç»­å¤©æ•°
        streak = 0
        for i in range(7):
            check_date = now.subtract(days=i+1)  # ä»æ˜¨å¤©å¼€å§‹ï¼ˆi+1ï¼‰
            date_str = check_date.format("YYYY-MM-DD")

            if date_str in activity_dates:
                streak += 1
                logger.debug(f"âœ… {date_str} æœ‰æ´»åŠ¨")
            else:
                logger.debug(f"âŒ {date_str} æ— æ´»åŠ¨ï¼Œè¿ç»­ä¸­æ–­")
                break  # ä¸€æ—¦æœ‰ä¸€å¤©æ²¡æ´»åŠ¨ï¼Œè¿ç»­å°±ä¸­æ–­äº†

        logger.info(f"è¿ç»­è´¡çŒ®å¤©æ•°: {streak} å¤©")
        return streak

    except Exception as e:
        logger.error(f"è®¡ç®—è¿ç»­å¤©æ•°å‡ºé”™: {e}")
        return 0


async def get_github_stats(token: str, username: str) -> Dict[str, Any]:
    """è·å– GitHub ç»Ÿè®¡æ•°æ®

    Args:
        token: GitHub Token
        username: GitHub ç”¨æˆ·å

    Returns:
        åŒ…å« GitHub æ•°æ®çš„å­—å…¸
    """
    # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ä»£ç 
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, _get_github_stats_sync, token, username)


def _get_github_stats_sync(token: str, username: str) -> Dict[str, Any]:
    """åŒæ­¥ç‰ˆæœ¬çš„ GitHub ç»Ÿè®¡æ•°æ®è·å–"""
    try:
        # æ—¶é—´è®¾ç½®
        yesterday = pendulum.now(TIMEZONE).subtract(days=1)
        yesterday_start = yesterday.start_of("day").in_timezone("UTC")
        yesterday_end = yesterday.end_of("day").in_timezone("UTC")
        yesterday_date = yesterday.format("YYYY-MM-DD")

        # è¯·æ±‚å¤´è®¾ç½®
        headers = {
            "Authorization": f"token {token}",
            "Accept": "application/vnd.github.v3+json",
        }

        all_activities = []

        # è·å–åˆ›å»ºçš„ PR
        search_url = "https://api.github.com/search/issues"
        pr_query = f"is:pr is:public author:{username} created:{yesterday_date}"
        pr_data, error = _make_api_request(
            search_url,
            headers,
            {"q": pr_query, "per_page": 100},
        )
        if pr_data:
            pr_items = pr_data.get("items", [])
            pr_activities = _process_search_items(pr_items, username, "pr")
            all_activities.extend(pr_activities)

        # è·å–åˆ›å»ºçš„ Issue
        issue_query = f"is:issue is:public author:{username} created:{yesterday_date}"
        issue_data, error = _make_api_request(
            search_url,
            headers,
            {"q": issue_query, "per_page": 100},
        )
        if issue_data:
            issue_items = issue_data.get("items", [])
            issue_activities = _process_search_items(issue_items, username, "issue")
            all_activities.extend(issue_activities)

        # è·å–å…¶ä»–äº‹ä»¶ï¼ˆåˆå¹¶ã€å…³é—­ã€Starã€Push ç­‰ï¼‰
        events_url = f"https://api.github.com/users/{username}/events"

        for page in range(1, 4):  # æ£€æŸ¥å‰3é¡µ
            page_params = {"page": page, "per_page": 30}
            events_data, error = _make_api_request(events_url, headers, page_params)

            if error or not events_data:
                break

            page_activities = _process_events(
                events_data, yesterday_start, yesterday_end
            )
            all_activities.extend(page_activities)

            if len(events_data) < 30:
                break

        # ç»Ÿè®¡æ•°æ®
        logger.info(f"æ€»å…±æ”¶é›†åˆ° {len(all_activities)} ä¸ªæ´»åŠ¨")

        commits_count = sum(
            a.get("commits", 0) for a in all_activities if a["type"] == "push"
        )
        prs_created = [a for a in all_activities if a["type"] == "pr" and a["action"] == "created"]
        prs_merged = [a for a in all_activities if a["type"] == "pr" and a["action"] == "merged"]
        issues_closed = [a for a in all_activities if a["type"] == "issue" and a["action"] == "closed"]
        stars = [a for a in all_activities if a["type"] == "star"]

        logger.info(f"ç»Ÿè®¡: commits={commits_count}, PRsåˆ›å»º={len(prs_created)}, PRsåˆå¹¶={len(prs_merged)}, Issueså…³é—­={len(issues_closed)}, Stars={len(stars)}")

        # è®¡ç®—è¿ç»­è´¡çŒ®å¤©æ•°
        week_streak = _calculate_streak(username, headers)

        return {
            "commits": commits_count,
            "prs_created": prs_created,
            "prs_merged": prs_merged,
            "issues_closed": issues_closed,
            "stars": stars,
            "week_streak": week_streak,
            "has_activity": len(all_activities) > 0,
        }

    except Exception as e:
        logger.error(f"GitHub æ•°æ®è·å–å¤±è´¥: {e}")
        return {
            "commits": 0,
            "prs_created": [],
            "prs_merged": [],
            "issues_closed": [],
            "stars": [],
            "week_streak": 0,
            "has_activity": False,
            "error": str(e),
        }


def format_github_message(data: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ– GitHub æ¶ˆæ¯"""
    if not data.get("has_activity"):
        return "ğŸ’» æ˜¨æ—¥ç¼–ç¨‹\nâ€¢ æ˜¨å¤©æ²¡æœ‰ GitHub æ´»åŠ¨"

    lines = ["ğŸ’» æ˜¨æ—¥ç¼–ç¨‹"]

    # Commits
    commits = data.get("commits", 0)
    if commits > 0:
        lines.append(f"â€¢ æäº¤äº† {commits} ä¸ª commits")

    # åˆ›å»ºçš„ PR
    prs_created = data.get("prs_created", [])
    for pr in prs_created[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
        lines.append(f"â€¢ åˆ›å»ºäº† PR: [{pr['title']}]({pr['url']}) ({pr['repo']})")

    # åˆå¹¶çš„ PR
    prs_merged = data.get("prs_merged", [])
    for pr in prs_merged[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ª
        lines.append(f"â€¢ åˆå¹¶äº† PR: [{pr['title']}]({pr['url']}) ({pr['repo']})")

    # å…³é—­çš„ Issue
    issues_closed = data.get("issues_closed", [])
    for issue in issues_closed[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ª
        lines.append(f"â€¢ å…³é—­äº† Issue: [{issue['title']}]({issue['url']}) ({issue['repo']})")

    # Star
    stars = data.get("stars", [])
    for star in stars[:2]:  # æœ€å¤šæ˜¾ç¤º2ä¸ª
        lines.append(f"â€¢ Star äº†é¡¹ç›®: [{star['repo']}]({star['url']})")

    # è¿ç»­å¤©æ•°
    week_streak = data.get("week_streak", 0)
    if week_streak > 0:
        lines.append(f"â€¢ æœ¬å‘¨è´¡çŒ®: è¿ç»­ {week_streak} å¤© ğŸ”¥")

    return "\n".join(lines)
